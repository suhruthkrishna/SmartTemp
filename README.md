# ğŸ§  SmartTemp: Teaching LLMs to Adjust Their Own Creativity  

**SmartTemp** is an experimental engine that lets **Large Language Models (LLMs)** *self-adjust their temperature dynamically* based on the intent and semantics of the prompt.  
Instead of manually tuning creativity, SmartTemp interprets the prompt context, estimates confidence, and adapts temperature intelligently â€” blending *precision* and *imagination* on its own.  

---

## ğŸ” Why SmartTemp?

Most LLM applications rely on a **static temperature value** â€” set once, used everywhere.  
But not every prompt deserves the same level of randomness.  

- â€œSummarize this paperâ€ â†’ needs *low temperature (factual)*  
- â€œWrite a poem about entropyâ€ â†’ needs *high temperature (creative)*  

SmartTemp automates that decision by reading the *prompt itself*, determining its nature, and **adapting the modelâ€™s temperature in real time**.

---

## âš™ï¸ How It Works

SmartTemp combines:
1. **Prompt Analysis Engine** â€“ Classifies the intent (`creative`, `factual`, `analytical`, `instructional`)  
2. **Confidence Scoring** â€“ Estimates how confidently it recognized the intent  
3. **Dynamic Temperature Scaling** â€“ Computes  

temperature = base_temp + (1 - confidence) * scale_factor

yaml
Copy code

so the less certain SmartTemp is, the more exploratory the LLM becomes.  
4. **LLM Integration Layer** â€“ Connects to **Ollama** or any OpenAI-compatible API  
5. **Gradio Interface** â€“ Displays real-time temperature/confidence graphs, prompt summaries, and responses  

---

## ğŸ§© System Architecture

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Prompt â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SmartTemp Analyzer â”‚
â”‚ (Categorization + Conf.) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Dynamic Temperature â”‚
â”‚ Adjustment Formula â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM Integration (Ollama â”‚
â”‚ or OpenAI-compatible) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Gradio Visualization UI â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

yaml
Copy code

---

## ğŸ’¡ Key Features

- ğŸ§  **Intent-Aware Temperature Tuning** â€“ Adjusts creativity based on prompt semantics  
- ğŸ“Š **Real-Time Visualization** â€“ Temperature & confidence graphs update per response  
- ğŸ”„ **Ollama-Compatible** â€“ Runs locally or with any OpenAI-style API  
- ğŸ¨ **Mock Mode** â€“ Simulates creative, factual, and analytical tones even without a live model  
- ğŸª„ **Fully Modular** â€“ Each component (analyzer, integration, interface) can be reused independently  

---

## ğŸ§  Example Interactions

| Prompt | Detected Type | Confidence | Assigned Temp | Behavior |
|--------|----------------|-------------|----------------|-----------|
| â€œWhat is the capital of Brazil?â€ | factual | 0.95 | 0.2 | Precise, single factual answer |
| â€œWrite a story about a robot in love.â€ | creative | 0.90 | 0.9 | Vivid, expressive storytelling |
| â€œExplain quantum computing in simple terms.â€ | analytical | 0.70 | 0.5 | Balanced technical clarity |

---

## ğŸš€ Quick Setup

> ğŸ§© SmartTemp is designed as a concept prototype.  
> You can run it locally to explore adaptive temperature logic â€” no hosting or credentials needed.

**Requirements**
```bash
pip install gradio openai
Run the Portal

bash
Copy code
python smarttemp.py
If you have Ollama installed and running, SmartTemp will automatically use it as the LLM backend.
Otherwise, it runs in mock mode, generating sample outputs for visualization.

ğŸ”¬ Example Output
vbnet
Copy code
Prompt: Explain gravity like Iâ€™m five
Category: Instructional
Confidence: 0.83
Assigned Temperature: 0.43
Response: Imagine you drop your toyâ€”it falls because the Earth is giving it a gentle hug called gravity.
ğŸ§­ Future Extensions
ğŸ” Replace rule-based classification with embedding-based semantic clustering

ğŸ” Add feedback loops for adaptive learning based on user rating

ğŸ§© Integrate with LangChain / LangGraph for dynamic reasoning chains

â˜ï¸ Deploy as an API layer for existing chat or agent systems

---

-Suhruth Krishna Yalamanchili
Data Scientist | AI Engineer | Writer
Exploring intersections of cognitive science and computational intelligence.



